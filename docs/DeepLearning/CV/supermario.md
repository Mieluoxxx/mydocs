---
title: YOLOå®æˆ˜--supermarioçš„æ£€æµ‹
---

## å‰ç«¯é¡µé¢çš„æ­å»º

ä½¿ç”¨çš„æ¡†æ¶ä¸ºStreamlitï¼Œæç®€å®ç”¨ä¸»ä¹‰

```python
#app.py
from pathlib import Path
from PIL import Image
import streamlit as st

import config
from utils import (
    load_model,
    infer_uploaded_image,
    infer_uploaded_video,
    infer_uploaded_webcam,
)

# è®¾ç½®é¡µé¢å¸ƒå±€
st.set_page_config(
    page_title="YOLOv8äº¤äº’ç•Œé¢",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ä¸»é¡µé¢æ ‡é¢˜
st.title("YOLOv8äº¤äº’ç•Œé¢")

# ä¾§è¾¹æ 
st.sidebar.header("æ·±åº¦å­¦ä¹ æ¨¡å‹é…ç½®")

# æ¨¡å‹é€‰é¡¹
task_type = st.sidebar.selectbox("é€‰æ‹©ä»»åŠ¡", ["æ£€æµ‹"])

model_type = None
if task_type == "æ£€æµ‹":
    model_type = st.sidebar.selectbox("é€‰æ‹©æ¨¡å‹", config.DETECTION_MODEL_LIST)
else:
    st.error("ç›®å‰åªå®ç°äº† 'æ£€æµ‹' åŠŸèƒ½")

confidence = float(st.sidebar.slider("é€‰æ‹©æ¨¡å‹ç½®ä¿¡åº¦", 30, 100, 50)) / 100

model_path = ""
if model_type:
    model_path = Path(config.DETECTION_MODEL_DIR, str(model_type))
else:
    st.error("è¯·åœ¨ä¾§è¾¹æ ä¸­é€‰æ‹©æ¨¡å‹")

# åŠ è½½é¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹
try:
    model = load_model(model_path)
except Exception as e:
    st.error(f"æ— æ³•åŠ è½½æ¨¡å‹ã€‚è¯·æ£€æŸ¥æŒ‡å®šçš„è·¯å¾„ï¼š{model_path}")

# å›¾åƒ/è§†é¢‘é€‰é¡¹
st.sidebar.header("å›¾åƒ/è§†é¢‘é…ç½®")
source_selectbox = st.sidebar.selectbox("é€‰æ‹©æ¥æº", config.SOURCES_LIST)

source_img = None
if source_selectbox == config.SOURCES_LIST[0]:  # å›¾åƒ
    infer_uploaded_image(confidence, model)
elif source_selectbox == config.SOURCES_LIST[1]:  # è§†é¢‘
    infer_uploaded_video(confidence, model)
elif source_selectbox == config.SOURCES_LIST[2]:  # æ‘„åƒå¤´
    infer_uploaded_webcam(confidence, model)
else:
    st.error("ç›®å‰åªå®ç°äº† 'å›¾åƒ' å’Œ 'è§†é¢‘' æ¥æº")

```

```python
#config.py
from pathlib import Path
import sys

# è·å–å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
file_path = Path(__file__).resolve()

# è·å–å½“å‰æ–‡ä»¶çš„çˆ¶ç›®å½•
root_path = file_path.parent

# å¦‚æœæ ¹è·¯å¾„å°šæœªæ·»åŠ åˆ°sys.pathåˆ—è¡¨ä¸­ï¼Œåˆ™å°†å…¶æ·»åŠ 
if root_path not in sys.path:
    sys.path.append(str(root_path))

# è·å–ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•çš„æ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„
ROOT = root_path.relative_to(Path.cwd())


# Source
SOURCES_LIST = ["Image", "Video", "Webcam"]


# DL æ¨¡å‹é…ç½®
DETECTION_MODEL_DIR = ROOT / "weights" / "detection"
YOLOv8n = DETECTION_MODEL_DIR / "yolov8n.pt"
YOLOv8s = DETECTION_MODEL_DIR / "yolov8s.pt"
YOLOv8m = DETECTION_MODEL_DIR / "yolov8m.pt"
YOLOv8l = DETECTION_MODEL_DIR / "yolov8l.pt"
YOLOv8x = DETECTION_MODEL_DIR / "yolov8x.pt"
mario = DETECTION_MODEL_DIR / "mario.pt"

DETECTION_MODEL_LIST = [
    "yolov8n.pt",
    "yolov8s.pt",
    "yolov8m.pt",
    "yolov8l.pt",
    "yolov8x.pt",
    "mario.pt",
]
```

```python
#utils.py
from ultralytics import YOLO
import streamlit as st
import cv2
from PIL import Image
import tempfile
import torch


def _display_detected_frames(conf, model, st_frame, image):
    """
    ä½¿ç”¨YOLOv8æ¨¡å‹åœ¨è§†é¢‘å¸§ä¸Šæ˜¾ç¤ºæ£€æµ‹åˆ°çš„å¯¹è±¡ã€‚
    :param conf (float): å¯¹è±¡æ£€æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼ã€‚
    :param model (YOLOv8): åŒ…å«YOLOv8æ¨¡å‹çš„`YOLOv8`ç±»çš„å®ä¾‹ã€‚
    :param st_frame (Streamlitå¯¹è±¡): ç”¨äºæ˜¾ç¤ºæ£€æµ‹åˆ°çš„è§†é¢‘çš„Streamlitå¯¹è±¡ã€‚
    :param image (numpyæ•°ç»„): è¡¨ç¤ºè§†é¢‘å¸§çš„numpyæ•°ç»„ã€‚
    :return: æ— 
    """
    # å°†å›¾åƒè°ƒæ•´ä¸ºæ ‡å‡†å¤§å°
    image = cv2.resize(image, (720, int(720 * (9 / 16))))

    # ä½¿ç”¨YOLOv8æ¨¡å‹åœ¨å›¾åƒä¸­é¢„æµ‹å¯¹è±¡
    res = model.predict(image, conf=conf)

    # åœ¨è§†é¢‘å¸§ä¸Šç»˜åˆ¶æ£€æµ‹åˆ°çš„å¯¹è±¡
    res_plotted = res[0].plot()
    st_frame.image(res_plotted, caption="æ£€æµ‹åˆ°çš„è§†é¢‘", channels="BGR", use_column_width=True)


@st.cache_resource
def load_model(model_path):
    """
    ä»æŒ‡å®šçš„model_pathåŠ è½½YOLOç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚

    å‚æ•°:
        model_path (str): YOLOæ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ã€‚

    è¿”å›:
        YOLOç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = YOLO(model_path).to(device)
    return model


def infer_uploaded_image(conf, model):
    """
    æ‰§è¡Œä¸Šä¼ å›¾åƒçš„æ¨æ–­
    :param conf: YOLOv8æ¨¡å‹çš„ç½®ä¿¡åº¦
    :param model: åŒ…å«YOLOv8æ¨¡å‹çš„`YOLOv8`ç±»çš„å®ä¾‹ã€‚
    :return: æ— 
    """
    source_img = st.sidebar.file_uploader(
        label="é€‰æ‹©å›¾åƒ...", type=("jpg", "jpeg", "png", "bmp", "webp")
    )

    col1, col2 = st.columns(2)

    with col1:
        if source_img:
            uploaded_image = Image.open(source_img)
            # å°†ä¸Šä¼ çš„å›¾åƒæ·»åŠ åˆ°é¡µé¢å¹¶æ·»åŠ æ ‡é¢˜
            st.image(image=source_img, caption="ä¸Šä¼ çš„å›¾åƒ", use_column_width=True)

    if source_img:
        if st.button("æ‰§è¡Œ"):
            with st.spinner("è¿è¡Œä¸­..."):
                res = model.predict(uploaded_image, conf=conf)
                boxes = res[0].boxes
                res_plotted = res[0].plot()[:, :, ::-1]

                with col2:
                    st.image(res_plotted, caption="æ£€æµ‹åˆ°çš„å›¾åƒ", use_column_width=True)
                    try:
                        with st.expander("æ£€æµ‹ç»“æœ"):
                            for box in boxes:
                                st.write(box.xywh)
                    except Exception as ex:
                        st.write("å°šæœªä¸Šä¼ å›¾åƒï¼")
                        st.write(ex)


def infer_uploaded_video(conf, model):
    """
    æ‰§è¡Œä¸Šä¼ è§†é¢‘çš„æ¨æ–­
    :param conf: YOLOv8æ¨¡å‹çš„ç½®ä¿¡åº¦
    :param model: åŒ…å«YOLOv8æ¨¡å‹çš„`YOLOv8`ç±»çš„å®ä¾‹ã€‚
    :return: æ— 
    """
    source_video = st.sidebar.file_uploader(label="é€‰æ‹©è§†é¢‘...")

    if source_video:
        st.video(source_video)

    if source_video:
        if st.button("æ‰§è¡Œ"):
            with st.spinner("è¿è¡Œä¸­..."):
                try:
                    tfile = tempfile.NamedTemporaryFile()
                    tfile.write(source_video.read())
                    vid_cap = cv2.VideoCapture(tfile.name)
                    st_frame = st.empty()
                    while vid_cap.isOpened():
                        success, image = vid_cap.read()
                        if success:
                            _display_detected_frames(conf, model, st_frame, image)
                        else:
                            vid_cap.release()
                            break
                except Exception as e:
                    st.error(f"åŠ è½½è§†é¢‘æ—¶å‡ºé”™ï¼š{e}")


def infer_uploaded_webcam(conf, model):
    """
    æ‰§è¡Œæ‘„åƒå¤´æ¨æ–­ã€‚
    :param conf: YOLOv8æ¨¡å‹çš„ç½®ä¿¡åº¦
    :param model: åŒ…å«YOLOv8æ¨¡å‹çš„`YOLOv8`ç±»çš„å®ä¾‹ã€‚
    :return: `æ— 
    """
    try:
        flag = st.button(label="åœæ­¢è¿è¡Œ")
        vid_cap = cv2.VideoCapture(0)  # æœ¬åœ°æ‘„åƒå¤´
        st_frame = st.empty()
        while not flag:
            success, image = vid_cap.read()
            if success:
                _display_detected_frames(conf, model, st_frame, image)
            else:
                vid_cap.release()
                break
    except Exception as e:
        st.error(f"åŠ è½½è§†é¢‘æ—¶å‡ºé”™ï¼š{str(e)}")

```




## åç«¯é€»è¾‘ï¼ˆYOLOï¼‰

1. å°†è§†é¢‘å¤„ç†æˆå¸§

```python
import cv2
import os
def video_to_frames(video_path, output_path, frame_interval=20):
    # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    cap = cv2.VideoCapture(video_path)

    # ç¡®ä¿è§†é¢‘æ–‡ä»¶å·²æˆåŠŸæ‰“å¼€
    if not cap.isOpened():
        print("Error: Could not open video.")
        return

    # è·å–è§†é¢‘çš„å¸§ç‡å’Œå¸§æ•°
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    print(f"Video FPS: {fps}")
    print(f"Total frames: {frame_count}")

    # åˆå§‹åŒ–è®¡æ•°å™¨
    frame_number = 0

    # é€å¸§è¯»å–è§†é¢‘å¹¶ä¿å­˜ä¸ºå›¾åƒæ–‡ä»¶
    while True:
        ret, frame = cap.read()
        if not ret:
            print(f"Error reading frame {frame_number}")
            break

        # æ¯éš” frame_interval å¸§ä¿å­˜ä¸€æ¬¡å›¾åƒ
        if frame_number % frame_interval == 0:
            # ç”Ÿæˆå›¾åƒæ–‡ä»¶å
            frame_filename = f"{output_path}/frame_{frame_number:04d}.jpg"

            # ä¿å­˜å›¾åƒæ–‡ä»¶
            cv2.imwrite(frame_filename, frame)

        frame_number += 1

    # é‡Šæ”¾è§†é¢‘å¯¹è±¡
    cap.release()

if __name__ == "__main__":
    # è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„å’Œè¾“å‡ºå¸§å›¾åƒçš„ç›®å½•
    input_video_path = os.getcwd() + "/data/raw/supermario.mp4"
    output_frames_path = os.getcwd() + "/data/processed/"

    # è°ƒç”¨å‡½æ•°è¿›è¡Œè½¬æ¢
    video_to_frames(input_video_path, output_frames_path)

```

2. åˆ©ç”¨colabè¿›è¡Œè®­ç»ƒ

```python
%%
%pip install ultralytics
%%

%%
from ultralytics import YOLO
from IPython.display import display, Image
%%

%%
# åŠ è½½æ•°æ®é›†
%pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="AKI-KEY")
project = rf.workspace("morgan-woods-aafya").project("supermario")
dataset = project.version(1).download("yolov8")
%%

%%
# è®­ç»ƒ
%yolo task=detect mode=train model=yolov8m.pt data={dataset.location}/data.yaml epochs=20 imgsz=640
%%

%%
# æ··æ·†çŸ©é˜µ
Image(filename=f'/content/runs/detect/train/confusion_matrix.png',width=600)
%%

%%
# è®­ç»ƒéªŒè¯ç»“æœ
Image(filename=f'/content/runs/detect/train/results.png',width=600)
%%

%%
# éªŒè¯
!yolo task=detect mode=val model=/content/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml
%%

%%
# æµ‹è¯•
!yolo task=detect mode=predict model=/content/runs/detect/train/weights/best.pt conf=0.5 source="/content/SuperMario-1/supermario.mp4"
%%
```

